Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.50 GB / 5.74 GB (8.7%)
Disk Space Avail:   322.47 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'Close',
 'time_limit': 60,
 'verbosity': 2}

Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.45 GB / 5.74 GB (7.8%)
Disk Space Avail:   322.46 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 30,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.35 GB / 5.74 GB (6.1%)
Disk Space Avail:   322.45 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:02:40
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.50 GB / 5.74 GB (8.7%)
Disk Space Avail:   322.44 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:05:42
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.55 GB / 5.74 GB (9.5%)
Disk Space Avail:   322.43 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 30,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:11:15
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 15.7s of the 109.8s of remaining time.
	-0.0931       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	7.16    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 17.1s of the 102.5s of remaining time.
	-0.0890       = Validation score (-SMAPE)
	0.02    s     = Training runtime
	4.90    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 19.5s of the 97.6s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 23.6s of the 94.3s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 30.9s of the 92.7s of remaining time.
	-0.0931       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	24.89   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 33.9s of the 67.8s of remaining time.
	-0.0960       = Validation score (-SMAPE)
	0.05    s     = Training runtime
	16.36   s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.0890       = Validation score (-SMAPE)
	0.32    s     = Training runtime
	4.90    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 61.05 s
Best model: SeasonalNaive
Best model score: -0.0890
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.60 GB / 5.74 GB (10.4%)
Disk Space Avail:   322.41 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:17:58
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 15.8s of the 110.8s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.05    s     = Training runtime
	6.12    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 17.4s of the 104.6s of remaining time.
	-0.0274       = Validation score (-SMAPE)
	0.05    s     = Training runtime
	4.88    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 19.9s of the 99.7s of remaining time.
	-0.0173       = Validation score (-SMAPE)
	3.09    s     = Training runtime
	0.24    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 24.1s of the 96.4s of remaining time.
	-0.0260       = Validation score (-SMAPE)
	1.89    s     = Training runtime
	0.15    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 31.4s of the 94.3s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	8.23    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 43.0s of the 86.0s of remaining time.
	-0.0218       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	7.99    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DirectTabular': 0.38, 'RecursiveTabular': 0.52, 'Theta': 0.1}
	-0.0089       = Validation score (-SMAPE)
	0.43    s     = Training runtime
	8.37    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 35.61 s
Best model: WeightedEnsemble
Best model score: -0.0089
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
Warning: 1 time series (100.0%) are shorter than 7 and cannot be predicted by RecursiveTabular\W0. Fallback model SeasonalNaive is used for these time series.
Warning: No path was specified for model, defaulting to: C:\Users\buayk\project\stock_test\AutogluonModels\ag-20250628_171918\
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.42 GB / 5.74 GB (7.4%)
Disk Space Avail:   322.35 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:37:07
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 15.4s of the 107.8s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	7.46    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 16.7s of the 100.0s of remaining time.
	-0.0274       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	4.17    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 19.2s of the 95.8s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 23.5s of the 94.1s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 31.1s of the 93.3s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	12.81   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 40.2s of the 80.4s of remaining time.
	-0.0218       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	8.46    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'Theta': 1.0}
	-0.0218       = Validation score (-SMAPE)
	0.30    s     = Training runtime
	8.46    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 38.58 s
Best model: Theta
Best model score: -0.0218
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: Theta
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: Theta
Beginning AutoGluon training... Time limit = 120s
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.54 GB / 5.74 GB (9.5%)
Disk Space Avail:   322.35 GB / 474.72 GB (67.9%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.54 GB / 5.74 GB (9.5%)
Disk Space Avail:   322.35 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training
Setting presets to: fast_training

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 453 rows (NaN fraction=31.1%), 1 time series. Median time series length is 453 (min=453, max=453). 
Provided train_data has 453 rows (NaN fraction=31.1%), 1 time series. Median time series length is 453 (min=453, max=453). 

Provided data contains following columns:

Provided data contains following columns:
	target: 'Close'
	target: 'Close'
	past_covariates:
	past_covariates:
		categorical:        []
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-06-29 00:38:31

Starting training. Start time is 2025-06-29 00:38:31
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 16.8s of the 117.8s of remaining time.
Training timeseries model Naive. Training for up to 16.8s of the 117.8s of remaining time.
	-0.0242       = Validation score (-SMAPE)
	-0.0242       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	0.03    s     = Training runtime
	3.83    s     = Validation (prediction) runtime
	3.83    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 19.0s of the 113.9s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 19.0s of the 113.9s of remaining time.
	-0.0170       = Validation score (-SMAPE)
	-0.0170       = Validation score (-SMAPE)
	0.02    s     = Training runtime
	0.02    s     = Training runtime
	4.20    s     = Validation (prediction) runtime
	4.20    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 21.9s of the 109.7s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 21.9s of the 109.7s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 27.1s of the 108.3s of remaining time.
Training timeseries model DirectTabular. Training for up to 27.1s of the 108.3s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 35.8s of the 107.4s of remaining time.
Training timeseries model ETS. Training for up to 35.8s of the 107.4s of remaining time.
	-0.0242       = Validation score (-SMAPE)
	-0.0242       = Validation score (-SMAPE)
	0.05    s     = Training runtime
	0.05    s     = Training runtime
	7.21    s     = Validation (prediction) runtime
	7.21    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 50.1s of the 100.1s of remaining time.
Training timeseries model Theta. Training for up to 50.1s of the 100.1s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	-0.0234       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	0.03    s     = Training runtime
	6.68    s     = Validation (prediction) runtime
	6.68    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
Fitting simple weighted ensemble.
	Ensemble weights: {'SeasonalNaive': 1.0}
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.0170       = Validation score (-SMAPE)
	-0.0170       = Validation score (-SMAPE)
	0.30    s     = Training runtime
	0.30    s     = Training runtime
	4.20    s     = Validation (prediction) runtime
	4.20    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 24.80 s
Total runtime: 24.80 s
Best model: SeasonalNaive
Best model: SeasonalNaive
Best model score: -0.0170
Best model score: -0.0170
data with frequency 'IRREG' has been resampled to frequency 'D'.
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.40 GB / 5.74 GB (6.9%)
Disk Space Avail:   322.33 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 361 rows (NaN fraction=31.0%), 1 time series. Median time series length is 361 (min=361, max=361). 

Provided data contains following columns:
	target: 'Close'
	past_covariates:
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-06-29 00:44:23
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 15.8s of the 110.3s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	6.48    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 17.3s of the 103.8s of remaining time.
	-0.0274       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	4.40    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 19.9s of the 99.3s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 24.3s of the 97.2s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 32.1s of the 96.4s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	8.19    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 44.1s of the 88.1s of remaining time.
	-0.0218       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	7.15    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'Theta': 1.0}
	-0.0218       = Validation score (-SMAPE)
	0.39    s     = Training runtime
	7.15    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 31.95 s
Best model: Theta
Best model score: -0.0218
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: Theta
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: Theta
Beginning AutoGluon training... Time limit = 120s
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
AutoGluon will save models to 'C:\Users\buayk\project\stock_test\ag_models'
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.46 GB / 5.74 GB (8.0%)
Disk Space Avail:   322.33 GB / 474.72 GB (67.9%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.3.1
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.46 GB / 5.74 GB (8.0%)
Disk Space Avail:   322.33 GB / 474.72 GB (67.9%)
===================================================
Setting presets to: fast_training
Setting presets to: fast_training

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': SMAPE,
 'freq': 'D',
 'hyperparameters': 'very_light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 10,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Close',
 'time_limit': 120,
 'verbosity': 2}

train_data with frequency 'IRREG' has been resampled to frequency 'D'.
train_data with frequency 'IRREG' has been resampled to frequency 'D'.
Provided train_data has 453 rows (NaN fraction=31.1%), 1 time series. Median time series length is 453 (min=453, max=453). 
Provided train_data has 453 rows (NaN fraction=31.1%), 1 time series. Median time series length is 453 (min=453, max=453). 

Provided data contains following columns:

Provided data contains following columns:
	target: 'Close'
	target: 'Close'
	past_covariates:
	past_covariates:
		categorical:        []
		categorical:        []
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']
		continuous (float): ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-06-29 00:45:44

Starting training. Start time is 2025-06-29 00:45:44
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']
Training timeseries model Naive. Training for up to 16.8s of the 117.5s of remaining time.
Training timeseries model Naive. Training for up to 16.8s of the 117.5s of remaining time.
	-0.0242       = Validation score (-SMAPE)
	-0.0242       = Validation score (-SMAPE)
	0.02    s     = Training runtime
	0.02    s     = Training runtime
	3.95    s     = Validation (prediction) runtime
	3.95    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 18.9s of the 113.6s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 18.9s of the 113.6s of remaining time.
	-0.0170       = Validation score (-SMAPE)
	-0.0170       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	0.04    s     = Training runtime
	4.32    s     = Validation (prediction) runtime
	4.32    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 21.8s of the 109.2s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 21.8s of the 109.2s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 26.8s of the 107.1s of remaining time.
Training timeseries model DirectTabular. Training for up to 26.8s of the 107.1s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 35.4s of the 106.2s of remaining time.
Training timeseries model ETS. Training for up to 35.4s of the 106.2s of remaining time.
	-0.0242       = Validation score (-SMAPE)
	-0.0242       = Validation score (-SMAPE)
	0.04    s     = Training runtime
	0.04    s     = Training runtime
	7.85    s     = Validation (prediction) runtime
	7.85    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 49.2s of the 98.3s of remaining time.
Training timeseries model Theta. Training for up to 49.2s of the 98.3s of remaining time.
	-0.0234       = Validation score (-SMAPE)
	-0.0234       = Validation score (-SMAPE)
	0.03    s     = Training runtime
	0.03    s     = Training runtime
	6.92    s     = Validation (prediction) runtime
	6.92    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
Fitting simple weighted ensemble.
	Ensemble weights: {'SeasonalNaive': 1.0}
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.0170       = Validation score (-SMAPE)
	-0.0170       = Validation score (-SMAPE)
	0.33    s     = Training runtime
	0.33    s     = Training runtime
	4.32    s     = Validation (prediction) runtime
	4.32    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'WeightedEnsemble']
Total runtime: 26.68 s
Total runtime: 26.68 s
Best model: SeasonalNaive
Best model: SeasonalNaive
Best model score: -0.0170
Best model score: -0.0170
data with frequency 'IRREG' has been resampled to frequency 'D'.
data with frequency 'IRREG' has been resampled to frequency 'D'.
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
data with frequency 'IRREG' has been resampled to frequency 'D'.
data with frequency 'IRREG' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
